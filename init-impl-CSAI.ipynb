{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.io\n",
    "import os\n",
    "import shutil\n",
    "try:\n",
    "    from urllib import urlretrieve # python2\n",
    "except:\n",
    "    from urllib.request import urlretrieve # python3\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import data as data\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch as T\n",
    "import torch\n",
    "device = T.device(\"cuda\")  # apply to Tensor or Module\n",
    "import time\n",
    "from tqdm import tqdm\n",
    "from train_objectives import SAD, SID\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "mat = scipy.io.loadmat( 'PaviaU.mat' )\n",
    "img = mat[ 'paviaU' ]\n",
    "\n",
    "# create a hyperspectral dataset object from the numpy array\n",
    "hypData = data.HypImg( img )\n",
    "\n",
    "# pre-process data to make the model easier to train\n",
    "hypData.pre_process( 'minmax' )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create data iterator objects for training and validation using the pre-processed data\n",
    "trainSamples = 200000\n",
    "valSamples = 100\n",
    "dataTrain = data.Iterator( dataSamples=hypData.spectraPrep[:trainSamples, :],\n",
    "                        targets=hypData.spectraPrep[:trainSamples, :], batchSize=4 )\n",
    "dataVal = data.Iterator( dataSamples=hypData.spectraPrep[trainSamples:trainSamples+valSamples, :],\n",
    "                        targets=hypData.spectraPrep[trainSamples:trainSamples+valSamples, :] )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# shuffle training data\n",
    "dataTrain.shuffle()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[2.6020e-02, 3.8839e-03, 2.7188e-03,  ..., 5.3631e-01, 5.3282e-01,\n",
       "         5.4252e-01],\n",
       "        [1.8890e-01, 3.5007e-02, 6.6050e-07,  ..., 5.7662e-01, 5.5350e-01,\n",
       "         5.4029e-01],\n",
       "        [1.2379e-01, 2.0571e-01, 1.1965e-01,  ..., 3.8978e-01, 3.8380e-01,\n",
       "         3.7368e-01],\n",
       "        ...,\n",
       "        [6.3573e-07, 2.6192e-01, 2.6573e-01,  ..., 4.7743e-01, 4.7934e-01,\n",
       "         4.7489e-01],\n",
       "        [2.8548e-02, 4.1982e-07, 4.6180e-02,  ..., 7.3426e-01, 7.4559e-01,\n",
       "         7.3720e-01],\n",
       "        [2.6362e-01, 1.1178e-01, 3.0850e-02,  ..., 8.4976e-01, 8.6138e-01,\n",
       "         8.8822e-01]])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data = torch.tensor(dataTrain.dataSamples.astype(np.float32))\n",
    "train_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([103, 50, 30, 10], [10, 30, 50, 103])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hypData.numBands\n",
    "encoderSize=[50,30,10]\n",
    "encoderSize=[hypData.numBands]+encoderSize\n",
    "decodersize=encoderSize[::-1]\n",
    "encoderSize,decodersize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def force_cudnn_initialization():\n",
    "    s = 32\n",
    "    dev = torch.device('cuda')\n",
    "    torch.nn.functional.conv2d(torch.zeros(s, s, s, s, device=dev), torch.zeros(s, s, s, s, device=dev))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -----------------------------------------------------------\n",
    "\n",
    "class Net(T.nn.Module):\n",
    "  def __init__(self):\n",
    "    super(Net, self).__init__()\n",
    "    self.enn1 = T.nn.Linear(103, 50)  # 64-16-2-16-64\n",
    "    self.enn2 = T.nn.Linear(50, 30)\n",
    "    self.enn3 = T.nn.Linear(30,10)\n",
    "    self.dnn3 = T.nn.Linear(10, 30)  # 64-16-2-16-64\n",
    "    self.dnn2 = T.nn.Linear(30, 50)\n",
    "    self.dnn1 = T.nn.Linear(50,103)\n",
    "\n",
    "  def encoder(self,x):\n",
    "    z= T.relu(self.enn1(x))\n",
    "    z= T.relu(self.enn2(z))\n",
    "    z= T.relu(self.enn3(z))\n",
    "    return z\n",
    "  \n",
    "  def decoder(self,x):\n",
    "    z= T.relu(self.dnn3(x))\n",
    "    z= T.relu(self.dnn2(z))\n",
    "    z= self.dnn1(z)\n",
    "    return z\n",
    "\n",
    "\n",
    "  def forward(self, x):\n",
    "    encoded=self.encoder(x)\n",
    "    decoded= self.decoder(encoded)\n",
    "    \n",
    "    return encoded,decoded\n",
    "    \n",
    "net=Net().to(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CSAI(nn.Module):\n",
    "  def __init__(self, num_bands: int=103):\n",
    "    super(CSAI, self).__init__()\n",
    "    self.num_bands = num_bands\n",
    "\n",
    "  def forward(self, input, target):\n",
    "    \"\"\"Spectral Angle Distance Objective\n",
    "    Implementation based on the mathematical formulation presented in 'https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7061924'\n",
    "    \n",
    "    Params:\n",
    "        input -> Output of the autoencoder corresponding to subsampled input\n",
    "                tensor shape: (batch_size, num_bands)\n",
    "        target -> Subsampled input Hyperspectral image (batch_size, num_bands)\n",
    "        \n",
    "    Returns:\n",
    "        angle: SAD between input and target\n",
    "    \"\"\"\n",
    "    try:\n",
    "      input_norm = torch.sqrt(torch.bmm(input.view(-1, 1, self.num_bands), input.view(-1, self.num_bands, 1)))\n",
    "      target_norm = torch.sqrt(torch.bmm(target.view(-1, 1, self.num_bands), target.view(-1, self.num_bands, 1)))\n",
    "      \n",
    "      summation = torch.bmm(input.view(-1, 1, self.num_bands), target.view(-1, self.num_bands, 1))\n",
    "      angle = summation/(input_norm * target_norm)\n",
    "      \n",
    "    \n",
    "    except ValueError:\n",
    "      return 0.0\n",
    "    \n",
    "    return angle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 103])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "inpu=torch.rand(1,103).to(device)\n",
    "outp=net(inpu)\n",
    "outp[1].shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "103"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hypData.numBands"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -----------------------------------------------------------\n",
    "\n",
    "force_cudnn_initialization()\n",
    "# 0. setup\n",
    "print(\"\\nBegin UCI digits auto-reduce-viz demo job \")\n",
    "T.manual_seed(1)\n",
    "np.random.seed(1)\n",
    "\n",
    "bat_size = 8184\n",
    "train_ldr = T.utils.data.DataLoader(train_data,\n",
    "batch_size=bat_size, shuffle=True)\n",
    "  # 2. create network\n",
    "print(\"\\nCreating 64-16-2-16-63 autoencoder \")\n",
    "net = Net().to(\"cuda:0\")\n",
    "\n",
    "# 3. train model\n",
    "max_epochs = 1300\n",
    "ep_log_interval = 5\n",
    "lrn_rate = 0.0001\n",
    "\n",
    "loss_func1 = T.nn.MSELoss()\n",
    "loss_func = CSAI()\n",
    "optimizer = T.optim.Adam(net.parameters(), lr=lrn_rate)\n",
    "\n",
    "print(\"\\nbat_size = %3d \" % bat_size)\n",
    "print(\"loss = \" + str(loss_func))\n",
    "print(\"optimizer = Adam\")\n",
    "print(\"max_epochs = %3d \" % max_epochs)\n",
    "print(\"lrn_rate = %0.3f \" % lrn_rate)\n",
    "\n",
    "print(\"\\nStarting training\")\n",
    "net = net.train()\n",
    "\n",
    "\n",
    "for epoch in range(0, max_epochs):\n",
    "  \n",
    "  loop= tqdm(enumerate(train_ldr), total=len(train_ldr),leave=True)\n",
    "  epoch_loss = 0  # for one full epoch\n",
    "  mseloss=0\n",
    "\n",
    "  iterator = iter(train_ldr)\n",
    "  \n",
    "  for (batch_idx, batch) in loop:\n",
    "    Z = next(iterator)\n",
    "    Z = Z.view(Z.size()[0], -1)\n",
    "    Z = Z.cuda()\n",
    "    \n",
    "    enc_out, dec_out = net(Z.float())\n",
    "    loss1 = loss_func(dec_out, Z.float())  \n",
    "    loss1 = torch.sum(loss1).float()\n",
    "    optimizer.zero_grad()\n",
    "    loss1.backward()\n",
    "    optimizer.step()\n",
    "    \n",
    "    X = batch.to(device)  # no targets needed\n",
    "    \n",
    "    '''optimizer.zero_grad()\n",
    "    oupt = net(X)\n",
    "    loss_obj = loss_func(oupt[1], X)  # note: X not Y'''\n",
    "    #loss_obj1=loss_func1(oupt[1],X)\n",
    "    epoch_loss += loss1.item()  # accumulate\n",
    "    #mseloss+=loss_obj1.item()\n",
    "    #loss_obj.backward()\n",
    "    #optimizer.step()\n",
    "    \n",
    "    loop.set_description(f\"Epoch [{epoch}/{max_epochs}]\")\n",
    "    loop.set_postfix(loss=str(epoch_loss))\n",
    "\n",
    "    \n",
    "\n",
    "  #if epoch % ep_log_interval == 0:\n",
    "    \n",
    "    \n",
    "    #print(\"epoch = %4d   loss = %0.4f\" % (epoch, epoch_loss)) \n",
    "print(\"Done \")\n",
    "\n",
    "# 4. plot digits using reduced form\n",
    "print(\"\\nCreating graph from encoded data \")\n",
    "net = net.eval()\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "torch.save(net, 'model_csai.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(net.state_dict(), 'net_model_sad.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "net.load_state_dict(torch.load('net_model_sad.pth'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trex=torch.tensor(hypData.spectraPrep.astype(np.float32))\n",
    "trex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataZ=net.encoder(trex.to(\"cuda\"))\n",
    "dataZ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataY = net.decoder(dataZ)\n",
    "dataY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imgZ = np.reshape(dataZ.to(\"cpu\").detach().numpy(), (hypData.numRows, hypData.numCols, -1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imgY = np.reshape(dataY.to(\"cpu\").detach().numpy(), (hypData.numRows, hypData.numCols, -1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imgX = np.reshape(hypData.spectraPrep, (hypData.numRows, hypData.numCols, -1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualise latent image using 3 out of the 10 dimensions\n",
    "colourImg = imgZ.copy()\n",
    "colourImg = colourImg[ :,:,np.argsort(-np.std(np.std(colourImg, axis=0), axis=0))[:3] ]\n",
    "colourImg /= np.max(np.max(colourImg, axis=0), axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(colourImg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save plot of latent vector of 'meadow' spectra\n",
    "fig = plt.figure()\n",
    "plt.plot(imgZ[576, 210, :])\n",
    "plt.xlabel('latent dimension')\n",
    "plt.ylabel('latent value')\n",
    "plt.title('meadow spectra')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save plot comparing pre-processed 'meadow' spectra input with decoder reconstruction\n",
    "fig = plt.figure()\n",
    "ax = plt.subplot(111)\n",
    "ax.plot(range(hypData.numBands),imgX[576, 210, :],label='pre-processed input')\n",
    "ax.plot(range(hypData.numBands),imgY[576, 210, :],label='reconstruction')\n",
    "plt.xlabel('band')\n",
    "plt.ylabel('value')\n",
    "plt.title('meadow spectra')\n",
    "ax.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
