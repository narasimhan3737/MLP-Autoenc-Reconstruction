{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.io\n",
    "import os\n",
    "import shutil\n",
    "try:\n",
    "    from urllib import urlretrieve # python2\n",
    "except:\n",
    "    from urllib.request import urlretrieve # python3\n",
    "#from loss_csai import CSAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import data as data\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch as T\n",
    "import torch\n",
    "device = T.device(\"cuda\")  # apply to Tensor or Module\n",
    "import time\n",
    "from tqdm import tqdm\n",
    "from train_objectives import SAD, SID\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "mat = scipy.io.loadmat( 'PaviaU.mat' )\n",
    "img = mat[ 'paviaU' ]\n",
    "\n",
    "# create a hyperspectral dataset object from the numpy array\n",
    "hypData = data.HypImg( img )\n",
    "\n",
    "# pre-process data to make the model easier to train\n",
    "hypData.pre_process( 'minmax' )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create data iterator objects for training and validation using the pre-processed data\n",
    "trainSamples = 200000\n",
    "valSamples = 100\n",
    "dataTrain = data.Iterator( dataSamples=hypData.spectraPrep[:trainSamples, :],\n",
    "                        targets=hypData.spectraPrep[:trainSamples, :], batchSize=4 )\n",
    "dataVal = data.Iterator( dataSamples=hypData.spectraPrep[trainSamples:trainSamples+valSamples, :],\n",
    "                        targets=hypData.spectraPrep[trainSamples:trainSamples+valSamples, :] )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# shuffle training data\n",
    "dataTrain.shuffle()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[3.7161e-02, 4.7642e-07, 2.0010e-02,  ..., 3.0253e-01, 2.8252e-01,\n",
       "         2.7870e-01],\n",
       "        [1.1500e-01, 3.2394e-07, 1.7817e-02,  ..., 6.5922e-01, 6.5760e-01,\n",
       "         6.5436e-01],\n",
       "        [1.2409e-01, 9.4485e-02, 6.1639e-02,  ..., 8.6213e-01, 8.7470e-01,\n",
       "         8.6294e-01],\n",
       "        ...,\n",
       "        [1.9427e-01, 8.5251e-02, 2.0370e-02,  ..., 7.7971e-01, 8.1818e-01,\n",
       "         8.4761e-01],\n",
       "        [1.8484e-01, 1.9653e-01, 8.9778e-02,  ..., 7.3595e-01, 7.5745e-01,\n",
       "         7.4349e-01],\n",
       "        [9.7970e-02, 4.1371e-02, 6.6498e-02,  ..., 8.7081e-01, 8.5914e-01,\n",
       "         8.5381e-01]])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data = torch.tensor(dataTrain.dataSamples.astype(np.float32))\n",
    "train_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([103, 50, 30, 10], [10, 30, 50, 103])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hypData.numBands\n",
    "encoderSize=[50,30,10]\n",
    "encoderSize=[hypData.numBands]+encoderSize\n",
    "decodersize=encoderSize[::-1]\n",
    "encoderSize,decodersize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def force_cudnn_initialization():\n",
    "    s = 32\n",
    "    dev = torch.device('cuda')\n",
    "    torch.nn.functional.conv2d(torch.zeros(s, s, s, s, device=dev), torch.zeros(s, s, s, s, device=dev))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -----------------------------------------------------------\n",
    "\n",
    "class Net(T.nn.Module):\n",
    "  def __init__(self):\n",
    "    super(Net, self).__init__()\n",
    "    self.enn1 = T.nn.Linear(103, 50)  # 64-16-2-16-64\n",
    "    self.enn2 = T.nn.Linear(50, 30)\n",
    "    self.enn3 = T.nn.Linear(30,10)\n",
    "    self.dnn3 = T.nn.Linear(10, 30)  # 64-16-2-16-64\n",
    "    self.dnn2 = T.nn.Linear(30, 50)\n",
    "    self.dnn1 = T.nn.Linear(50,103)\n",
    "\n",
    "  def encoder(self,x):\n",
    "    z= T.relu(self.enn1(x))\n",
    "    z= T.relu(self.enn2(z))\n",
    "    z= T.relu(self.enn3(z))\n",
    "    return z\n",
    "  \n",
    "  def decoder(self,x):\n",
    "    z= T.relu(self.dnn3(x))\n",
    "    z= T.relu(self.dnn2(z))\n",
    "    z= self.dnn1(z)\n",
    "    return z\n",
    "\n",
    "\n",
    "  def forward(self, x):\n",
    "    encoded=self.encoder(x)\n",
    "    decoded= self.decoder(encoded)\n",
    "    \n",
    "    return encoded,decoded\n",
    "    \n",
    "net=Net().to(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 103])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "inpu=torch.rand(1,103).to(device)\n",
    "outp=net(inpu)\n",
    "outp[1].shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "103"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hypData.numBands"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Begin UCI digits auto-reduce-viz demo job \n",
      "\n",
      "Creating 64-16-2-16-63 autoencoder \n",
      "\n",
      "bat_size = 8184 \n",
      "loss = <function csam at 0x000001E42EAECF70>\n",
      "optimizer = Adam\n",
      "max_epochs =  15 \n",
      "lrn_rate = 0.001 \n",
      "\n",
      "Starting training\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                           | 0/25 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'NoneType' object has no attribute 'backward'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Input \u001b[1;32mIn [16]\u001b[0m, in \u001b[0;36m<cell line: 35>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     50\u001b[0m \u001b[38;5;66;03m#loss1 = torch.sum(loss1).float()\u001b[39;00m\n\u001b[0;32m     51\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[1;32m---> 52\u001b[0m \u001b[43mloss1\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m()\n\u001b[0;32m     53\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mstep()\n\u001b[0;32m     55\u001b[0m X \u001b[38;5;241m=\u001b[39m batch\u001b[38;5;241m.\u001b[39mto(device)  \u001b[38;5;66;03m# no targets needed\u001b[39;00m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'backward'"
     ]
    }
   ],
   "source": [
    "# -----------------------------------------------------------\n",
    "\n",
    "force_cudnn_initialization()\n",
    "# 0. setup\n",
    "print(\"\\nBegin UCI digits auto-reduce-viz demo job \")\n",
    "T.manual_seed(1)\n",
    "np.random.seed(1)\n",
    "\n",
    "bat_size = 8184\n",
    "train_ldr = T.utils.data.DataLoader(train_data,\n",
    "batch_size=bat_size, shuffle=True)\n",
    "  # 2. create network\n",
    "print(\"\\nCreating 64-16-2-16-63 autoencoder \")\n",
    "net = Net().to(\"cuda:0\")\n",
    "\n",
    "# 3. train model\n",
    "max_epochs = 15\n",
    "ep_log_interval = 5\n",
    "lrn_rate = 0.001\n",
    "\n",
    "loss_func1 = T.nn.MSELoss()\n",
    "#loss_func = SID()\n",
    "optimizer = T.optim.Adam(net.parameters(), lr=lrn_rate)\n",
    "\n",
    "print(\"\\nbat_size = %3d \" % bat_size)\n",
    "print(\"loss = \" + str(csam))\n",
    "print(\"optimizer = Adam\")\n",
    "print(\"max_epochs = %3d \" % max_epochs)\n",
    "print(\"lrn_rate = %0.3f \" % lrn_rate)\n",
    "\n",
    "print(\"\\nStarting training\")\n",
    "net = net.train()\n",
    "\n",
    "\n",
    "for epoch in range(0, max_epochs):\n",
    "  time.sleep(0.5)\n",
    "  loop= tqdm(enumerate(train_ldr), total=len(train_ldr),leave=True)\n",
    "  epoch_loss = 0  # for one full epoch\n",
    "  mseloss=0\n",
    "\n",
    "  iterator = iter(train_ldr)\n",
    "  \n",
    "  for (batch_idx, batch) in loop:\n",
    "    Z = next(iterator)\n",
    "    Z = Z.view(Z.size()[0], -1)\n",
    "    Z = Z.cuda()\n",
    "    \n",
    "    enc_out, dec_out = net(Z.float())\n",
    "    loss1 = csam(dec_out, Z.float())  \n",
    "    #loss1 = torch.sum(loss1).float()\n",
    "    optimizer.zero_grad()\n",
    "    loss1.backward()\n",
    "    optimizer.step()\n",
    "    \n",
    "    X = batch.to(device)  # no targets needed\n",
    "    \n",
    "    '''optimizer.zero_grad()\n",
    "    oupt = net(X)\n",
    "    loss_obj = loss_func(oupt[1], X)  # note: X not Y'''\n",
    "    #loss_obj1=loss_func1(oupt[1],X)\n",
    "    epoch_loss += loss1.item()  # accumulate\n",
    "    #mseloss+=loss_obj1.item()\n",
    "    #loss_obj.backward()\n",
    "    #optimizer.step()\n",
    "    \n",
    "    loop.set_description(f\"Epoch [{epoch}/{max_epochs}]\")\n",
    "    loop.set_postfix(loss=str(epoch_loss))\n",
    "\n",
    "    \n",
    "\n",
    "  #if epoch % ep_log_interval == 0:\n",
    "\n",
    "    \n",
    "    #print(\"epoch = %4d   loss = %0.4f\" % (epoch, epoch_loss)) \n",
    "print(\"Done \")\n",
    "\n",
    "# 4. plot digits using reduced form\n",
    "print(\"\\nCreating graph from encoded data \")\n",
    "net = net.eval()\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p=net(Z.float())\n",
    "p.detach()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "torch.save(net, 'model_csa1.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(net.state_dict(), 'net_model_csa1.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "net.load_state_dict(torch.load('net_model_csa1.pth'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trex=torch.tensor(hypData.spectraPrep.astype(np.float32))\n",
    "trex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataZ=net.encoder(trex.to(\"cuda\"))\n",
    "dataZ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataY = net.decoder(dataZ)\n",
    "dataY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imgZ = np.reshape(dataZ.to(\"cpu\").detach().numpy(), (hypData.numRows, hypData.numCols, -1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imgY = np.reshape(dataY.to(\"cpu\").detach().numpy(), (hypData.numRows, hypData.numCols, -1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imgX = np.reshape(hypData.spectraPrep, (hypData.numRows, hypData.numCols, -1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualise latent image using 3 out of the 10 dimensions\n",
    "colourImg = imgZ.copy()\n",
    "colourImg = colourImg[ :,:,np.argsort(-np.std(np.std(colourImg, axis=0), axis=0))[:3] ]\n",
    "colourImg /= np.max(np.max(colourImg, axis=0), axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(colourImg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save plot of latent vector of 'meadow' spectra\n",
    "fig = plt.figure()\n",
    "plt.plot(imgZ[576, 210, :])\n",
    "plt.xlabel('latent dimension')\n",
    "plt.ylabel('latent value')\n",
    "plt.title('meadow spectra')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save plot comparing pre-processed 'meadow' spectra input with decoder reconstruction\n",
    "fig = plt.figure()\n",
    "ax = plt.subplot(111)\n",
    "ax.plot(range(hypData.numBands),imgX[576, 210, :],label='pre-processed input')\n",
    "ax.plot(range(hypData.numBands),imgY[576, 210, :],label='reconstruction')\n",
    "plt.xlabel('band')\n",
    "plt.ylabel('value')\n",
    "plt.title('meadow spectra')\n",
    "ax.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.7690, 0.7507, 0.7591])"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss_func = SID()\n",
    "inpt1=torch.rand(3,103)\n",
    "inpt2=torch.rand(3,103)\n",
    "cos = T.nn.CosineSimilarity(dim=1, eps=1e-6)\n",
    "outp=cos(inpt1,inpt2)\n",
    "outp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input=Z\n",
    "target=dec_out\n",
    "eps=1e5\n",
    "\n",
    "normalize_inp = (input/torch.sum(input, dim=0)) + eps\n",
    "normalize_tar = (target/torch.sum(target, dim=0)) + eps\n",
    "sid = torch.sum(normalize_inp * torch.log(normalize_inp / normalize_tar) + normalize_tar * torch.log(normalize_tar / normalize_inp))\n",
    "sid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "decout = dec_out.detach()\n",
    "decout.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def csa1(input, target):\n",
    "    norm_r = torch.nn.functional.normalize(torch.transpose(input,0,0),dim=0)\n",
    "    norm_t = torch.nn.functional.normalize(torch.transpose(target,0,0),dim=0)\n",
    "    mult = torch.sum(torch.multiply(norm_r,norm_t),dim=0)\n",
    "    return (1-(torch.sum(mult)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "csat = torch.nn.CosineSimilarity(dim=0, eps=1e-08)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def csaim(input, target):\n",
    "    normalize_r = (input/torch.sum(input, dim=0)) \n",
    "    normalize_t = (target/torch.sum(target, dim=0))\n",
    "    mult = torch.sum(torch.multiply(normalize_r,normalize_t),dim=0)\n",
    "    multo = 1-(torch.sum(mult))\n",
    "    return multo\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def csa(input, target):\n",
    "    normalize_r = (input/torch.sum(input, dim=0)) \n",
    "    normalize_t = (target/torch.sum(target, dim=0))\n",
    "    mult = torch.multiply(normalize_r,normalize_t).sum()\n",
    "    return 1-(mult.sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "normalize_r = (input/torch.sum(input, dim=0)) \n",
    "normalize_t = (target/torch.sum(target, dim=0))\n",
    "mult = torch.multiply(normalize_r,normalize_t).sum()\n",
    "1-mult"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "csaloss = torch.acos(mult)\n",
    "csaloss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CSAI(nn.Module):\n",
    "  def __init__(self, num_bands: int=156):\n",
    "    super(SAD, self).__init__()\n",
    "    self.num_bands = num_bands\n",
    "\n",
    "  def forward(self, input, target):\n",
    "    \"\"\"Spectral Angle Distance Objective\n",
    "    Implementation based on the mathematical formulation presented in 'https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7061924'\n",
    "    \n",
    "    Params:\n",
    "        input -> Output of the autoencoder corresponding to subsampled input\n",
    "                tensor shape: (batch_size, num_bands)\n",
    "        target -> Subsampled input Hyperspectral image (batch_size, num_bands)\n",
    "        \n",
    "    Returns:\n",
    "        angle: SAD between input and target\n",
    "    \"\"\"\n",
    "    try:\n",
    "      input_norm = torch.sqrt(torch.bmm(input.view(-1, 1, self.num_bands), input.view(-1, self.num_bands, 1)))\n",
    "      target_norm = torch.sqrt(torch.bmm(target.view(-1, 1, self.num_bands), target.view(-1, self.num_bands, 1)))\n",
    "      \n",
    "      summation = torch.bmm(input.view(-1, 1, self.num_bands), target.view(-1, self.num_bands, 1))\n",
    "      angle = torch.acos(summation/(input_norm * target_norm))\n",
    "      \n",
    "    \n",
    "    except ValueError:\n",
    "      return 0.0\n",
    "    \n",
    "    return angle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def csam(input, target):\n",
    "    normalize_r = (input/torch.sum(input, dim=0)) \n",
    "    normalize_t = (target/torch.sum(target, dim=0))\n",
    "    mult = torch.multiply(normalize_r,normalize_t).sum()\n",
    "    1-mult"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
