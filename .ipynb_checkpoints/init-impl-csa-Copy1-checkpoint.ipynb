{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'loss_csai'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Input \u001b[1;32mIn [4]\u001b[0m, in \u001b[0;36m<cell line: 8>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m:\n\u001b[0;32m      7\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01murllib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mrequest\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m urlretrieve \u001b[38;5;66;03m# python3\u001b[39;00m\n\u001b[1;32m----> 8\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mloss_csai\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m CSAI\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'loss_csai'"
     ]
    }
   ],
   "source": [
    "import scipy.io\n",
    "import os\n",
    "import shutil\n",
    "try:\n",
    "    from urllib import urlretrieve # python2\n",
    "except:\n",
    "    from urllib.request import urlretrieve # python3\n",
    "from loss_csai import CSAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import data as data\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch as T\n",
    "import torch\n",
    "device = T.device(\"cuda\")  # apply to Tensor or Module\n",
    "import time\n",
    "from tqdm import tqdm\n",
    "from train_objectives import SAD, SID\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mat = scipy.io.loadmat( 'PaviaU.mat' )\n",
    "img = mat[ 'paviaU' ]\n",
    "\n",
    "# create a hyperspectral dataset object from the numpy array\n",
    "hypData = data.HypImg( img )\n",
    "\n",
    "# pre-process data to make the model easier to train\n",
    "hypData.pre_process( 'minmax' )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'data' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[1;32mIn [2]\u001b[0m, in \u001b[0;36m<cell line: 4>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      2\u001b[0m trainSamples \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m200000\u001b[39m\n\u001b[0;32m      3\u001b[0m valSamples \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m100\u001b[39m\n\u001b[1;32m----> 4\u001b[0m dataTrain \u001b[38;5;241m=\u001b[39m \u001b[43mdata\u001b[49m\u001b[38;5;241m.\u001b[39mIterator( dataSamples\u001b[38;5;241m=\u001b[39mhypData\u001b[38;5;241m.\u001b[39mspectraPrep[:trainSamples, :],\n\u001b[0;32m      5\u001b[0m                         targets\u001b[38;5;241m=\u001b[39mhypData\u001b[38;5;241m.\u001b[39mspectraPrep[:trainSamples, :], batchSize\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m4\u001b[39m )\n\u001b[0;32m      6\u001b[0m dataVal \u001b[38;5;241m=\u001b[39m data\u001b[38;5;241m.\u001b[39mIterator( dataSamples\u001b[38;5;241m=\u001b[39mhypData\u001b[38;5;241m.\u001b[39mspectraPrep[trainSamples:trainSamples\u001b[38;5;241m+\u001b[39mvalSamples, :],\n\u001b[0;32m      7\u001b[0m                         targets\u001b[38;5;241m=\u001b[39mhypData\u001b[38;5;241m.\u001b[39mspectraPrep[trainSamples:trainSamples\u001b[38;5;241m+\u001b[39mvalSamples, :] )\n",
      "\u001b[1;31mNameError\u001b[0m: name 'data' is not defined"
     ]
    }
   ],
   "source": [
    "# create data iterator objects for training and validation using the pre-processed data\n",
    "trainSamples = 200000\n",
    "valSamples = 100\n",
    "dataTrain = data.Iterator( dataSamples=hypData.spectraPrep[:trainSamples, :],\n",
    "                        targets=hypData.spectraPrep[:trainSamples, :], batchSize=4 )\n",
    "dataVal = data.Iterator( dataSamples=hypData.spectraPrep[trainSamples:trainSamples+valSamples, :],\n",
    "                        targets=hypData.spectraPrep[trainSamples:trainSamples+valSamples, :] )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'dataTrain' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[1;32mIn [3]\u001b[0m, in \u001b[0;36m<cell line: 2>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# shuffle training data\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m \u001b[43mdataTrain\u001b[49m\u001b[38;5;241m.\u001b[39mshuffle()\n",
      "\u001b[1;31mNameError\u001b[0m: name 'dataTrain' is not defined"
     ]
    }
   ],
   "source": [
    "# shuffle training data\n",
    "dataTrain.shuffle()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[9.7489e-02, 3.6928e-07, 7.3859e-03,  ..., 9.7230e-01, 9.7969e-01,\n",
       "         9.6713e-01],\n",
       "        [1.4417e-01, 1.0214e-01, 4.0192e-02,  ..., 7.3267e-01, 7.5074e-01,\n",
       "         7.3156e-01],\n",
       "        [2.4532e-01, 1.1560e-01, 3.8752e-02,  ..., 7.5369e-01, 7.5271e-01,\n",
       "         7.6059e-01],\n",
       "        ...,\n",
       "        [1.4318e-01, 6.7022e-02, 2.0183e-02,  ..., 6.5575e-01, 6.5118e-01,\n",
       "         6.2947e-01],\n",
       "        [5.5991e-07, 5.3752e-02, 1.7861e-01,  ..., 4.4793e-01, 4.4513e-01,\n",
       "         4.5857e-01],\n",
       "        [1.9870e-01, 1.1437e-01, 1.9182e-02,  ..., 7.5100e-01, 7.4086e-01,\n",
       "         7.4050e-01]])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data = torch.tensor(dataTrain.dataSamples.astype(np.float32))\n",
    "train_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([103, 50, 30, 10], [10, 30, 50, 103])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hypData.numBands\n",
    "encoderSize=[50,30,10]\n",
    "encoderSize=[hypData.numBands]+encoderSize\n",
    "decodersize=encoderSize[::-1]\n",
    "encoderSize,decodersize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def force_cudnn_initialization():\n",
    "    s = 32\n",
    "    dev = torch.device('cuda')\n",
    "    torch.nn.functional.conv2d(torch.zeros(s, s, s, s, device=dev), torch.zeros(s, s, s, s, device=dev))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -----------------------------------------------------------\n",
    "\n",
    "class Net(T.nn.Module):\n",
    "  def __init__(self):\n",
    "    super(Net, self).__init__()\n",
    "    self.enn1 = T.nn.Linear(103, 50)  # 64-16-2-16-64\n",
    "    self.enn2 = T.nn.Linear(50, 30)\n",
    "    self.enn3 = T.nn.Linear(30,10)\n",
    "    self.dnn3 = T.nn.Linear(10, 30)  # 64-16-2-16-64\n",
    "    self.dnn2 = T.nn.Linear(30, 50)\n",
    "    self.dnn1 = T.nn.Linear(50,103)\n",
    "\n",
    "  def encoder(self,x):\n",
    "    z= T.relu(self.enn1(x))\n",
    "    z= T.relu(self.enn2(z))\n",
    "    z= T.relu(self.enn3(z))\n",
    "    return z\n",
    "  \n",
    "  def decoder(self,x):\n",
    "    z= T.relu(self.dnn3(x))\n",
    "    z= T.relu(self.dnn2(z))\n",
    "    z= self.dnn1(z)\n",
    "    return z\n",
    "\n",
    "\n",
    "  def forward(self, x):\n",
    "    encoded=self.encoder(x)\n",
    "    decoded= self.decoder(encoded)\n",
    "    \n",
    "    return encoded,decoded\n",
    "    \n",
    "net=Net().to(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 103])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "inpu=torch.rand(1,103).to(device)\n",
    "outp=net(inpu)\n",
    "outp[1].shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "103"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hypData.numBands"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Begin UCI digits auto-reduce-viz demo job \n",
      "\n",
      "Creating 64-16-2-16-63 autoencoder \n",
      "\n",
      "bat_size = 8184 \n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'csaim' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[1;32mIn [14]\u001b[0m, in \u001b[0;36m<cell line: 26>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     23\u001b[0m optimizer \u001b[38;5;241m=\u001b[39m T\u001b[38;5;241m.\u001b[39moptim\u001b[38;5;241m.\u001b[39mAdam(net\u001b[38;5;241m.\u001b[39mparameters(), lr\u001b[38;5;241m=\u001b[39mlrn_rate)\n\u001b[0;32m     25\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mbat_size = \u001b[39m\u001b[38;5;132;01m%3d\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m bat_size)\n\u001b[1;32m---> 26\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mloss = \u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mstr\u001b[39m(\u001b[43mcsaim\u001b[49m))\n\u001b[0;32m     27\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124moptimizer = Adam\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     28\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmax_epochs = \u001b[39m\u001b[38;5;132;01m%3d\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m max_epochs)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'csaim' is not defined"
     ]
    }
   ],
   "source": [
    "# -----------------------------------------------------------\n",
    "\n",
    "force_cudnn_initialization()\n",
    "# 0. setup\n",
    "print(\"\\nBegin UCI digits auto-reduce-viz demo job \")\n",
    "T.manual_seed(1)\n",
    "np.random.seed(1)\n",
    "\n",
    "bat_size = 8184\n",
    "train_ldr = T.utils.data.DataLoader(train_data,\n",
    "batch_size=bat_size, shuffle=True)\n",
    "  # 2. create network\n",
    "print(\"\\nCreating 64-16-2-16-63 autoencoder \")\n",
    "net = Net().to(\"cuda:0\")\n",
    "\n",
    "# 3. train model\n",
    "max_epochs = 15\n",
    "ep_log_interval = 5\n",
    "lrn_rate = 0.001\n",
    "\n",
    "loss_func1 = T.nn.MSELoss()\n",
    "#loss_func = SID()\n",
    "optimizer = T.optim.Adam(net.parameters(), lr=lrn_rate)\n",
    "\n",
    "print(\"\\nbat_size = %3d \" % bat_size)\n",
    "print(\"loss = \" + str(csaim))\n",
    "print(\"optimizer = Adam\")\n",
    "print(\"max_epochs = %3d \" % max_epochs)\n",
    "print(\"lrn_rate = %0.3f \" % lrn_rate)\n",
    "\n",
    "print(\"\\nStarting training\")\n",
    "net = net.train()\n",
    "\n",
    "\n",
    "for epoch in range(0, max_epochs):\n",
    "  time.sleep(0.5)\n",
    "  loop= tqdm(enumerate(train_ldr), total=len(train_ldr),leave=True)\n",
    "  epoch_loss = 0  # for one full epoch\n",
    "  mseloss=0\n",
    "\n",
    "  iterator = iter(train_ldr)\n",
    "  \n",
    "  for (batch_idx, batch) in loop:\n",
    "    Z = next(iterator)\n",
    "    Z = Z.view(Z.size()[0], -1)\n",
    "    Z = Z.cuda()\n",
    "    \n",
    "    enc_out, dec_out = net(Z.float())\n",
    "    loss1 = csaim(dec_out, Z.float())  \n",
    "    loss1 = torch.sum(loss1).float()\n",
    "    optimizer.zero_grad()\n",
    "    loss1.backward()\n",
    "    optimizer.step()\n",
    "    \n",
    "    X = batch.to(device)  # no targets needed\n",
    "    \n",
    "    '''optimizer.zero_grad()\n",
    "    oupt = net(X)\n",
    "    loss_obj = loss_func(oupt[1], X)  # note: X not Y'''\n",
    "    #loss_obj1=loss_func1(oupt[1],X)\n",
    "    epoch_loss += loss1.item()  # accumulate\n",
    "    #mseloss+=loss_obj1.item()\n",
    "    #loss_obj.backward()\n",
    "    #optimizer.step()\n",
    "    \n",
    "    loop.set_description(f\"Epoch [{epoch}/{max_epochs}]\")\n",
    "    loop.set_postfix(loss=str(epoch_loss))\n",
    "\n",
    "    \n",
    "\n",
    "  #if epoch % ep_log_interval == 0:\n",
    "\n",
    "    \n",
    "    #print(\"epoch = %4d   loss = %0.4f\" % (epoch, epoch_loss)) \n",
    "print(\"Done \")\n",
    "\n",
    "# 4. plot digits using reduced form\n",
    "print(\"\\nCreating graph from encoded data \")\n",
    "net = net.eval()\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p=net(Z.float())\n",
    "p.detach()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "torch.save(net, 'model_csa1.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(net.state_dict(), 'net_model_csa1.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "net.load_state_dict(torch.load('net_model_csa1.pth'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trex=torch.tensor(hypData.spectraPrep.astype(np.float32))\n",
    "trex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataZ=net.encoder(trex.to(\"cuda\"))\n",
    "dataZ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataY = net.decoder(dataZ)\n",
    "dataY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imgZ = np.reshape(dataZ.to(\"cpu\").detach().numpy(), (hypData.numRows, hypData.numCols, -1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imgY = np.reshape(dataY.to(\"cpu\").detach().numpy(), (hypData.numRows, hypData.numCols, -1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imgX = np.reshape(hypData.spectraPrep, (hypData.numRows, hypData.numCols, -1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualise latent image using 3 out of the 10 dimensions\n",
    "colourImg = imgZ.copy()\n",
    "colourImg = colourImg[ :,:,np.argsort(-np.std(np.std(colourImg, axis=0), axis=0))[:3] ]\n",
    "colourImg /= np.max(np.max(colourImg, axis=0), axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(colourImg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save plot of latent vector of 'meadow' spectra\n",
    "fig = plt.figure()\n",
    "plt.plot(imgZ[576, 210, :])\n",
    "plt.xlabel('latent dimension')\n",
    "plt.ylabel('latent value')\n",
    "plt.title('meadow spectra')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save plot comparing pre-processed 'meadow' spectra input with decoder reconstruction\n",
    "fig = plt.figure()\n",
    "ax = plt.subplot(111)\n",
    "ax.plot(range(hypData.numBands),imgX[576, 210, :],label='pre-processed input')\n",
    "ax.plot(range(hypData.numBands),imgY[576, 210, :],label='reconstruction')\n",
    "plt.xlabel('band')\n",
    "plt.ylabel('value')\n",
    "plt.title('meadow spectra')\n",
    "ax.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.7690, 0.7507, 0.7591])"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss_func = SID()\n",
    "inpt1=torch.rand(3,103)\n",
    "inpt2=torch.rand(3,103)\n",
    "cos = T.nn.CosineSimilarity(dim=1, eps=1e-6)\n",
    "outp=cos(inpt1,inpt2)\n",
    "outp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input=Z\n",
    "target=dec_out\n",
    "eps=1e5\n",
    "\n",
    "normalize_inp = (input/torch.sum(input, dim=0)) + eps\n",
    "normalize_tar = (target/torch.sum(target, dim=0)) + eps\n",
    "sid = torch.sum(normalize_inp * torch.log(normalize_inp / normalize_tar) + normalize_tar * torch.log(normalize_tar / normalize_inp))\n",
    "sid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "decout = dec_out.detach()\n",
    "decout.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "def csa1(input, target):\n",
    "    norm_r = torch.nn.functional.normalize(torch.transpose(input,0,0),dim=0)\n",
    "    norm_t = torch.nn.functional.normalize(torch.transpose(target,0,0),dim=0)\n",
    "    mult = torch.multiply(norm_r,norm_t).sum()\n",
    "    return (1-(mult.sum()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "csat = torch.nn.CosineSimilarity(dim=0, eps=1e-08)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def csam(input, target):\n",
    "    normalize_r = (input/torch.sum(input, dim=0)) \n",
    "    normalize_t = (target/torch.sum(target, dim=0))\n",
    "    mult = torch.sum(torch.multiply(normalize_r,normalize_t),dim=0)\n",
    "    mult = 1-(torch.sum(mult))\n",
    "    return mult\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def csa(input, target):\n",
    "    normalize_r = (input/torch.sum(input, dim=0)) \n",
    "    normalize_t = (target/torch.sum(target, dim=0))\n",
    "    mult = torch.multiply(normalize_r,normalize_t).sum()\n",
    "    return 1-(mult.sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "normalize_r = (input/torch.sum(input, dim=0)) \n",
    "normalize_t = (target/torch.sum(target, dim=0))\n",
    "mult = torch.multiply(normalize_r,normalize_t).sum()\n",
    "1-mult"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "csaloss = torch.acos(mult)\n",
    "csaloss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CSAI(nn.Module):\n",
    "  def __init__(self, num_bands: int=156):\n",
    "    super(SAD, self).__init__()\n",
    "    self.num_bands = num_bands\n",
    "\n",
    "  def forward(self, input, target):\n",
    "    \"\"\"Spectral Angle Distance Objective\n",
    "    Implementation based on the mathematical formulation presented in 'https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7061924'\n",
    "    \n",
    "    Params:\n",
    "        input -> Output of the autoencoder corresponding to subsampled input\n",
    "                tensor shape: (batch_size, num_bands)\n",
    "        target -> Subsampled input Hyperspectral image (batch_size, num_bands)\n",
    "        \n",
    "    Returns:\n",
    "        angle: SAD between input and target\n",
    "    \"\"\"\n",
    "    try:\n",
    "      input_norm = torch.sqrt(torch.bmm(input.view(-1, 1, self.num_bands), input.view(-1, self.num_bands, 1)))\n",
    "      target_norm = torch.sqrt(torch.bmm(target.view(-1, 1, self.num_bands), target.view(-1, self.num_bands, 1)))\n",
    "      \n",
    "      summation = torch.bmm(input.view(-1, 1, self.num_bands), target.view(-1, self.num_bands, 1))\n",
    "      angle = torch.acos(summation/(input_norm * target_norm))\n",
    "      \n",
    "    \n",
    "    except ValueError:\n",
    "      return 0.0\n",
    "    \n",
    "    return angle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
